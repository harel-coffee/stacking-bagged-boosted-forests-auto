---
title: "Stacking utilizado nos experimentos"
author: "Raphael Rodrigues Campos"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    keep_tex: yes
  html_document: default
header-includes: \usepackage{multirow} \usepackage[utf8]{inputenc} \usepackage{mathtools}
---

# Stacking
  
Stacking também conhecido como "Stacked Generalization" é um método para combinar multiplos
classificadores usando algoritmos de aprendizados heterogêneos $L_1, ..., L_N$ sobre um único
conjunto de dados $D$, que consiste de exemplos $e_i = (x_i, y_i)$, onde $x_i$ é o vetor
de atributos e $y_i$ sua classificação.

## Stacking Framework

O staking framework utilizado é baseado no descrito em [1] David H. Wolpert, "Stacked Generalization", Neural Networks, 5, 241--259, 1992. Foi utilizado um stacking de dois níveis (o framework não se limita a apenas dois níveis, é possível fazer o stacking de quantos níveis julgar necessário), que pode ser dividido em duas fases. Na primeira fase, um conjunto de classificadores do nível base $C_1, C_2, ..., C_N$ é gerado, onde $C_i = L_i(D)$. Na segunda fase um classidicador do meta-nível aprende a combinar as saídas dos classificadores do nível base. 

Para gerar o conjunto de treino para o aprendizado do classificador do meta-nível, pode-se aplicar o procedimento **leave-one-out** ou **cross validation**.
Por questões óbvias de custo computacional, é utilizado nesse relatório cross validation, mais especificamente **5-fold cross validation**. Cada classificador do nível base aprende usando $D - F_k$ deixando o k-ésimo *fold* para teste: $\forall i = 1,...,N : \forall k = 1,...,5 : C^{k}_i = L_i(D-F_k)$. Agora, os classificadores recém aprendidos são usados para gerar as predições para $\forall x_j \in F_k:\hat{y}_j^i=C^k_i(x_j)$. O conjunto de treino do meta-nível consiste de exemplos da seguinte forma $((\hat{y}_i^1,..., \hat{y}_i^N), y_i)$, onde os atributos são as predicóes do s classificadores do nível base e a classe é a classe correta sabida de antemão.

### Exemplo

Esse procedimento pode parecer complicado, mas na verdade é simples. Como um exemplo, vamos gerar alguns dados sintéticos com a função "saída = soma do três componentes de entrada". Nosso conjunto de treino D consiste de 5 pares de entrada e saída $\{((0,0,0),0), ((1,0,0),1), ((1,2,0),3), ((1,1,1),3), ((1,-2,4),3)\}$, todas as entradas sem ruídos. Vamos rotular esses 5 pares de entrada e saída como $F_1$ até $F_5$ (Então por exemplo $D - F_2$ consiste dos quatros pares $\{((0,0,0),0), ((1,2,0),3), ((1,1,1),3), ((1,-2,4),3)\}$). Nesse exemplo, temos dois classificadores do nível base $C_1$ e $C_2$, e um único classificador do meta-nível $\Gamma$. O conjunto de treino do meta-nível $D'$ é dado pelo cinco pares de entrada e saída $\{$ (($C_1^k(F_k), C_2^k(F_k)$), componente de saída de $F_k) : \forall k \in \{1,...,5\}$ e $C_i^k = L_i(D-F_k)\}$ (Esse espaço do meta-nível possui duas dimensões de entrada  e uma de saída). Ou seja, a instância do conjunto de treino do meta-nível correspondente a $k = 1$ tem o componetne de saída 0 e entrada $(C_1^1((0,0,0)), C_2^1((0,0,0)))$. Agora nos é dado um exemplo de teste no formato do nível base $(x_1, x_2, x_3)$. Nós predizemos seu valor com $\Gamma((C_1((x_1, x_2, x_3)), (C_2((x_1, x_2, x_3)))$, onde $C_1$ e $C_2$ foram treinados com todo $D$, e $\Gamma$ com $D'$. Em outras palavras, nós predizemos o valor da entrada de teste $q = (x_1, x_2, x_3)$ treinando $\Gamma$ em $D'$ e assim predizendo a entrada formada pelas predições do valor do exemplo de teste $q$, de ambos classificadores do nível base $C_1$ e $C_2$, que por suas vezes foram treinados com todo $D$.

## Stacking com distribuições de probabilidade

Usar probabilidade para gerar o conjunto de treino do meta-nível é mais vantajoso já que disponibiliza mais informação acerca das predições feitas pelos classificadores do nível base. Essa informações adicionais permitem que não seja usado somente a predição, mas também o confiança de cada classificador do nível base.

Nessa abordagem, cada classificador do nível base prediz uma Distribuição de Probabilidade (DP) sobre todas as classes possíveis. Então, a predição do classificador do nível base $C$ apliacado a um exemplo $x$ é a DP: $p^C(x) = (p^C(c_1|x), ... , p^C(c_m|x))$, onde $\{c_1, ..., c_m\}$ é o conjunto de possíveis valores para as classes e $p^C(c_i|x))$ descreve a probabilidade do exemplo $x$ ser da classe $c_i$ estimado pelo classificador $C$. A  classe $c_j$ com maior probalidade será classe predita por $C$. Dessa forma, os atributos do meta-nível serão as probabilidade preditas para cada classe possível por cada classificador do nível base. O número total de atributos no conjunto de treino do meta-nível seria $Nm$, $m$ atributos para cada classificador do nível base.

Os experimentos rodados até então utilizaram o stacking framework com DPs.

## Stacking com DP, Entropia e probabilidade máxima

No artigo [2] Is combining classifiers better than selecting the best one, os autores propões uma extensão para esse framework com DP espandindo o número de meta-atributos. Esse novos meta-atributos seriam:

- A distribuição de probabilidade mutiplicadao pela probabilidade máxima: $p_{C_j} = p^{C_j}(c_i|x) \times M_{C_j}(x) = p^{C_j}(c_i|x) \times max_{i=1}^{m}(p^{C_j}(c_i|x))$, $\forall i \in \{1,...,m\}$ e $\forall j \in \{1,...,N\}$.

- As entropias das distripuições de probabilidade: $E_{C_j}(x) = -\sum_{i=1}^{m}p^{C_j}(c_i|x).\log_2(p^{C_j}(c_i|x))$.

O número total de atributos do meta-nível é $N(2m+1)$.

A idea é obter ainda mais informações em relação a predição feita pelos classificadores do nível base. Como Ting and Witten (1999) disseram: o uso de distribuição de probabilidades tem a vantagemde capturar não apenas as predições dos classificadores do nível base, mas também, suas certezas. Os atributos adicionais tentam capturar a certeza de forma mais explicita. 

Entropia é uma medida de incerteza. Quanto maior a entropia da distribuição menor é a certeza sobre a predição. A probabilidade máxima de uma DP $M_{C_j}$ também contém informação sobre certeza da predição: quanto maior $M_{C_j}$ for mais certo daquela resposta o classificador do nível base está, e vice versa.

Esse é uma ideia para aplicarmos futuramente. Nesse momento continuarei utilizanto somente a DP.

# SVM 

Nessa seção, vamos dar uma visão geral sobre Support Vector Machine(SVM) utilizado nos experimentos.

Seja $x_i \in R^d$ um vetor de caracteríticas. Nosso objetivo é projetar um classificador, por exemplo, que associa a cada vetor $x_i$ um rótulo positivo ou negativo baseado no critério desejado.

O vetor $x_i$ é classificador olhando o sinal do resultado do função $f(x_i,w) = w^Tx_i$.O objetivo é aprender a estimar os paramêtros $w \in R^d$ de tal forma que o sinal é positvo seo vetor $x_i$ pertence a classe negativa e negativo caso contrário. De  fato, na formulação padrão do SVM o objetivo é ter o o valor da função no mínimo 1  no primeiro caso, e no máximo -1* no segundo, impondo uma margem.

O paramêtr $w$ é estimado ou aprendido ajustando o função a um conjunto de treino de $n$ pares de exemplos $(x_i,y_i),i=1,…,n$, onde $y_i \in \{-1,1\}$ são os rótulos dos correspondentes vetores de caracteríticas. A qualidade do ajuste é mensurada pela função de perda que, em SVMs padrões SVMs, é a **hinge loss**:

\begin{equation}
l_i(w,x_i)=\max(0,1-y_iw^Tx_i))
\end{equation}

Note que a **hinge loss** é zero apenas se o valor de $w^Tx_i$ é no mínimo 1 ou no máximo -1, dependendo do rótulo de $y_i$.

Somente ajustar ao treino é normalmente insuficiente. Para que a função seja capaz de generalizar para dados nunca visto, é preferível um **trade off** entre a acurácia do ajuste e complexidade do modelo. Dessa forma, é adionado um termo de regularição a formula, o regularizador na formulação padrão é mensurado pela normado vetor de pesos $\mid w\mid^2$. Tirando-se a média da perda de todo os exemplos de treino e adicionando-se a ela o regularizador ponderado pelo paramêtro $\lambda$ produz uma função objetiva de perda regularizada:

\begin{equation}
  E(w)  = \lambda||w||^2+\frac{1}{n} \sum_{i=1}^{n}\max(0,1-y_if(w,x)
\end{equation}
Note que a função objetiva é convexa, desse modo existe um único ótimo global.

A função $f(x_i,w)$ considerada até aqui é linear em sem viés. A subseção seguinte discute como um termo de viés pode ser adicionado ao SVM.

## Adicionando viés

É comum adicionar a funcão do SVM um termo de viés b, e considerar a nova função $f(x_i,w) = w^{T}x_i + b$. Na prática termo de viés pode ser crucial para ajustar os dados de treino de forma ótima, já que não há razão que o produto interno $w^{T}x_i$ devesse ser naturalmente centrado em zero. Alguns algoritmos de aprendizado do SVM podem estimar ambos $w$ e $b$ diretamente. Porém, outros algoritmos como **Stochastic Gradient Descente(SGC)** e **Stochastic Dual Coordinate Ascent (SDCA)** não podem (ambos usados pelo LIBLINEAR). Nesse caso, uma simples solução é adcionar um termo constante $B > 0$ ao dado, por exemplo, considere os vetores estendidos:

$\bar{x_i}=\begin{bmatrix} x_i \\ B \end{bmatrix}$, $\bar{w}=\begin{bmatrix} w \\ w_b\end{bmatrix}$.

De modo que função incorpore implicitamente o termo de viés $b = Bw_b$: 
\begin{equation}
  \bar{w}^T\bar{x_i} = w^Tx_i + Bw_b
\end{equation}

A desvantagem dessa redução é que o termo $w^2_b$ torna parte do regularizador do SVM, que encole o viés $b$ em direção a zero. Esse efeito pode ser aliviado tomando valor de $B$ suficientemente grandes, por causa disso $||w||^2 >> w^2_b$ e o efeito de encolimento pode ser ignorado.
Infelizmente, fazer $B$ muito grande faz o problema numericamente desbalanciado, assim uma troca justa entre encolhimento e estabilidade é buscada. Tipicamente, isso é obtido normalizando o dado, para que tenha uma norma Euclidiana unitária e, então, escolhendo $B \in [1,10]$.

Referências:

  - http://www.vlfeat.org/api/svm-fundamentals.html
  - https://www.csie.ntu.edu.tw/~cjlin/papers/liblinear.pdf 

