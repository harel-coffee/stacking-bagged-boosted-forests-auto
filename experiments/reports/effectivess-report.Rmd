---
title: "Effectivess comparison report"
author: "Raphael Rodrigues Campos"
date: "January 17, 2016"
output:
  pdf_document:
    keep_tex: yes
  html_document: default
header-includes: \usepackage{multirow}
---

Eu implementei o BROOF usando Extremely Randomized Trees no lugar da RF, gerando o algoritmo que chamei de BERT (Boosted Extremely Randomized Trees).

A própria ERT se sai melhor em alguns datasets do que a RF. Portanto, era de se esperar
que a BERT se saísse um pouco melhor que o BROOF, como pode-se verificar no arquivo anexo.

O arquivo anexo possui uma tabela comparando todos os métodos rodados até agora.

Além da implementaćão do BERT, eu também implementei método de ensemble "Stacked Generalization" descrito em [1] David H. Wolpert, "Stacked Generalization", Neural Networks, 5, 241--259, 1992.

O método comb1 na tabela é o stacking de 2 níveis para combinaćão dos métodos LazyNN\_RF e BROOF. No nível do zero do stacking foram utilizados os classificadores LazyNN_RF e BROOF para gerar o conjunto de treino do nível 1. No nível 1 foi utilizado uma RF com 200 árvores.

Os resultados apresentados são promissores. Sobretudo quando se trata de métrica microf1, onde tivemos mais ganhos significativos.


```{r, message=FALSE, warning=FALSE, echo=FALSE}
source("~/Documents/Master Degree/Master Project/Implementation/LazyNN_RF/experiments/reports/utils.R")

dir_path = "~/Documents/Master\ Degree/Master\ Project/Implementation/LazyNN_RF/release/results/results_python/"

# load results from directory
# and extract information such as
# metric (f1-measure), models and
# datasets used
trials = 5
results = result.load.dir(dir_path, trials)

f1 = results[[1]]
models_labels = toupper(results[[2]])
datasets_labels = toupper(results[[3]])

```

# Resultados

```{r, results="asis", echo=F}
f1_avg = round(apply(f1, c(1,2), mean)*100, digits=2)
f1_sd = round(apply(f1, c(1,2), sd)*100, digits=2)

winner_table <- stats.sigficant.winner.table(f1, f1_avg, models_labels,
                                             datasets_labels, p.adjust = "hommel")

print_meas(f1_avg, f1_sd, models_labels, datasets_labels,
           c("microF1", "macroF1"), winner_table, 
           caption = "Comparaćão entre todos os métodos")
```

Legenda para os métodos:

- BERT: Boosted Extremely Randomized Trees
- LXT: Lazy Extremely Randomized Trees
- RF: Random Forest com 200 árvores
- RF1000: Random Forest com 1000 árvores
- XT: Extremely Randomized Trees com 200 árvores
- XT1000: Extremely Randomized Trees com 1000 árvores
- COMB1: Stacking (Lazy + BROOF)
- COMB2: Stacking (LXT + BERT)
- COMB3: Stacking (Lazy + BROOF + LXT + BERT)
- COMBSOTA: Stacking (KNN + RF + SVM + NB)