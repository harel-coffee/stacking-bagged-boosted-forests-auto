---
title: "Effectivess comparison report"
author: "Raphael Rodrigues Campos"
date: "January 17, 2016"
output:
  pdf_document:
    keep_tex: yes
  html_document: default
header-includes: \usepackage{multirow} \usepackge{natbib}
bibliography: ../references.bibtex
---
```{r, message=FALSE, warning=FALSE, echo=FALSE}
source("~/Documents/Master Degree/Master Project/Implementation/LazyNN_RF/experiments/reports/utils.R")

method_importance <- function(methods, importance, distance="Kendall"){
  x <- scale(importance, center=F, colSums(importance))
  y <- t(apply(x, 2, order, decreasing=T))

  rank <- RankAggreg(y, length(methods), distance=distance, verbose=F)

  return(list(x, rank))
}

fff <- function(importance, methods){
  x <- scale(importance, center=F, colSums(importance))
  ord <- order(methods)
  means <- apply(x, 1, mean)
  
  std <- apply(x, 1, sd)
  
  winner <- stats.sigficant.winner(t(x), methods, 0,p.adjust = "hommel")

  return(list(winner[methods, methods[which.max(means)]], means, std))
}
```

# Caso de Estudo: Classificação Automática de Texto


## Resultados e discussões

A Tabela \ref{tab:base} sumariza os resultados da avaliação empirica de algums algoritmos estado-da-arte para classificação de texto e os algoritmos propostos baseado na **Extremelly Randomized Tree**(doravante Extra-trees).

Primeiro aspecto que pode ser observado é que as *Extra-Trees* por si só melhoram a eficácia da *Random Forest* em dois conjuntos de dados(empatando nos outros dois). Esse resultado comprova que *Extra-Trees* também são mais robustas a ruídos e atributos irrelevante como mostrado em [@GEURTS2006], além disso, mostra que isso se mantém quando aplicadas a tarefas de classificação de texto. Todavia, está longe de figurar o cojunto dos melhores classificadores dentre os algoritmos analizados. O SVM continua sendo o melhor classificador, sendo o melhor classificador em todos os 4 conjuntos de dados. Isso não é supresa, já que o SVM é bom para aprender quando aplicado a dados de alta dimensionalidade e com natural robustês para atributos ruidosos e irrelevantes.

Logo em seguida vem *BERT (Boosted Extremelly Randomized Trees)*, o algoritmo é uma extensão do *BROOF* proposto em [@Salles:2015:BEO:2766462.2767747]. Os resultados obtidos com a abordagem comprova nossa intuição de que a simples substituição da RF pela Extra-Trees traria ganhos expressivos no poder de generalização do *BROOF*, tornando a técnica ainda mais competitiva se comparada a outros classificadores.

Outra proposta foi a substituíção da RF pela *Extra-Trees* no algorimo *LazyNN_RF*, na esperação de ganho no poder de generalização do mesmo. É nítido que o uso das Extra-Trees no algoritmo LXT proporcionou um ganho sobretudo nos conjuntos de dados 20NG e REUTERS90, quando comparado ao algoritmo Lazy.

Esses resultados reforçam que as Extra-Trees são mais robustas a ruídos que as RF, todavia estão aquém se comparadas a capacidade do SVM de lidar com dados de alta dimensionalidade e ruidosos. Porém, com uso das técnicas apresentadas em [@Salles:Proposal:2015] pode-se aumentar a capacidade desses algoritmos de lidar com dados ruidosos tarnando-os assim mais competitivos ou muitas vezes melhores que a os algoritmos a presentados na Tabela \ref{tab:base}.

```{r, message=FALSE, warning=FALSE, echo=FALSE, results="asis", echo=F, cache = T}
dir_path = "../../../release/results/hidra/text/base/"

winning_counts <- build_table(dir_path, caption = "Comparação entres métodos de base", label = "tab:base")

tab <- xtable(winning_counts[order(apply(winning_counts, 1, sum), decreasing = T), ],
                caption = "Número de vezes que cada algoritmo foi o mais eficaz", label = "tab:win_count:base")
print(tab)
```

### Stacking

Nessa seção contrastamos o aumento do poder de generalização ao combinarmos técnicas altamente eficázes, tais como LazyNN_RF, BROOF, BERT e LazyExtraTrees(LXT), com o ganho proporcionado pela combinação de alguns classificadores estado-da-arte para classificação automática de texto.

Stacking      |   Descrição
------------- | -------------------------
COMB1         | BROOF + Lazy
COMB2         | BERT + LXT
COMB3         | BROOF + Lazy + BERT + LXT
COMBSOTA      | SVM + KNN + XT + RF + NB
COMBALL       | Stacking de todos

Table: Legenda para os stacking. Os classificadores reportados na descrição são todos do nível base, para todos os stackings foi utilizado RF como classificador do meta-nível.


Pode-se observar na Tabela \ref{tab:stacking} que o algoritmo COMBALL obteve efetividade superior (ou, pelo menos empatou) a todos os classificadores baseados em stacking e os classficadores da Tabela \ref{tab:base}. Isso pode parecer obvio, porém podemos notar que não há necessidade de combinar todos os classificadores para obtenção de resultados satisfatórios, por exemplo, o algoritmo COMB3 que combina algoritmos basedos em florestas aleatórias proporciona resultados similares aos obtidos com COMBALL, porém, a um custo computacional muito menor. Pode-se notar que o único conjunto de dados que de fato COMBALL ganhou do COMB3 foi o 20NG. Um outro aspecto interessante que pode-se notar da Tabela \ref{tab:stacking} é que os métodos baseados em floresta aleatórias, tais como Lazy, LXT, BROOF e Bert, tem papel fundamental na melhoria na acurácia dos métodos de stacking COMBALL. Pode-se observar que o algoritmo COMBSOTA não tem um resultado extraordinário em todos os conjuntos de dados se compararmos ao COMB3, todavia, quando é feito uma mesclagem do COMBSOTA e COMB3, orinando-se o stacking COMBALL, são obtidos resultados extraordinários, assim indicando a força que esses métodos dão para o aumento do poder generalização do stacking nesse tipo de tarefa.

```{r, message=FALSE, warning=FALSE, echo=FALSE, results="asis", echo=F, cache=T}

dir_path = "~/Documents/Master\ Degree/Master\ Project/Implementation/LazyNN_RF/release/results/results_comparison/stacking/"


winning_counts <- build_table(dir_path, caption = "Comparação entre os métodos de stacking", label = "tab:stacking")


tab <- xtable(winning_counts[order(apply(winning_counts, 1, sum), decreasing = T), ],
                caption = "Número de vezes que cada algoritmo foi o mais eficaz", label = "tab:win_count_stacking")
print(tab)
```


A pergunta que fica é: Qual a influência de cada classificador de base na predição final do stacking?

## Quais classificadores são realmente importantes para o stacking?

Todos os classificadores empregados no COMBALL contribuem equivalentemente para predição final do stacking? Para tentar responder essa pergunta foi utilizado uma característica única do classificador utilizado no meta-nível, a RF, que é medida de importância de atributos.

As Tabelas \ref{tab:imp20ng}, \ref{tab:imp4uni} e \ref{tab:impacm} mostram a estimativa do peso de cada classificador de base para predição de uma dada classe no conjunto dados 20NG, 4UNI e ACM respectivamente. Para o conjunto de dados 20NG temos que os classificadores do nível base que mais contribuíram para a predição do stacking foram NB, LXT, BERT, LAZY e BROOF. Para o conjunto 4UNI foram BERT, BROOF, LAZY, XT, RF. Para o conjunto ACM tivemos o LAZY, BERT, NB, BROOF, XT como maiores contribuintes. Apesar do SVM ter sido o melhor classificador de base para todos os conjuntos de dados, ele não figurou o grupo de classificadores de base que mais contribuíram para predição do COMBALL, todavia, isso não quer dizer que o SVM não é bom para stacking. Na verdade, o que podemos concluir é que as predições feitas pelo SVM são correlatas as predições feitas por algum dos classificadores mencionados. Pode-se observar na Tabela \ref{tab:stacking} que há um ganho expressivo de eficácia do stacking COMBSOTA quando são acrescidos os métodos BERT, BROOF, LAZY e LXT (originando-se o stacking COMBALL), isso comprova que as predições feitas pelos classificadores de base estados-da-arte (NB, RF, XT, KNN e SVM) são de certa forma correlatos, assim, não gerando ganhos tão expressivos com stacking. O ponto interessante é que podemos notar que de fato os classificadores BERT, BROOF, LAZY e LXT são complementares e bom para serem combinados com stacking, já que tem alta eficácia e geram modelos um tanto distintos, isso pode ser notado pelo bom desempenho do stacking COMB3.


```{r, message=FALSE, warning=FALSE, echo=FALSE, results="asis", echo=F, cache=F}

features<-c(0.00416682,0.00384382,0.00473317,0.00574452,0.00678629,0.00723175,0.00606995,0.00662127,0.00660509,0.00618221,0.00519496,0.007641,0.00690356,0.00781109,0.00771279,0.00309312,0.00465655,0.00810851,0.0051701, 0.00430634,0.0063561, 0.00659134,0.00699816,0.00588157,0.00824719,0.01082329,0.00788998,0.00829354,0.01186754,0.00875978,0.00758563,0.00739696,0.00775201,0.00693237,0.00726298,0.00497382,0.0045908, 0.00695152,0.00595362,0.00278102,0.00689311,0.00625094,0.00689353,0.00595031,0.00948243,0.00894834,0.00817311,0.00721071,0.00843101,0.00770308,0.0102244, 0.00939226,0.00705032,0.00955723,0.00676961,0.00533863,0.00761051,0.00813294,0.00461341,0.00492648,0.00707117,0.00661532,0.00810998,0.00602167,0.00902592,0.0064316,0.00989747,0.00780652,0.00693678,0.00994476,0.00843226,0.00691646,0.00851768,0.00503709,0.00553, 0.00984284,0.00888697,0.00857425,0.00721446,0.00430472,0.001155,0.00151049,0.00173556,0.00135396,0.00118895,0.00122814,0.0021986, 0.00113943,0.00121045,0.00114719,0.00168157,0.00104549,0.00110651,0.00113438,0.00131363,0.00120552,0.00152631,0.0013619, 0.0013293, 0.00160923,0.00725907,0.00954753,0.00692973,0.00689005,0.00816458,0.00926929,0.00557303,0.01424852,0.01496219,0.016045,0.01379279,0.01343142,0.00808542,0.01714905,0.01674761,0.02351044,0.01469687,0.01359458,0.00633595,0.00387658,0.00167106,0.00257812,0.00192811,0.00177082,0.00113125,0.001047,0.00097868,0.00078878,0.0008721, 0.00063934,0.00144696,0.00046922,0.00143435,0.00086635,0.00092943,0.00096742,0.00119769,0.00044053,0.0013745, 0.00257544,0.00305524,0.00271517,0.00274705,0.00304622,0.00174952,0.00330782,0.00302048,0.00256659,0.00329845,0.00344629,0.00543236,0.00433251,0.0018262, 0.00325539,0.00469926,0.0013711,0.00267694,0.00466353,0.00348488,0.00269804,0.00510456,0.00288161,0.00414597,0.00328219,0.00294239,0.00388603,0.00449326,0.00605479,0.00475961,0.00495738,0.00596133,0.00643221,0.00516684,0.00476104,0.0054305, 0.00369202,0.00483549,0.00438652,0.00467596,0.00321638)

methods <- c("broof","lazy","bert","lxt","svm","nb","knn","rf","xt")
features <- matrix(features,byrow = T, nrow=9)
results <- method_importance(methods, features, distance="Spearman")

m <- results[[1]]
rank <- results[[2]]
m <- `rownames<-`(m, methods)
tab <- xtable(t(m[rank$top.list,]), caption = "Importância de cada classificador no stacking COMBALL para o conjunto de dados 20NG", label = "tab:imp20ng")
print(tab)

results <- fff(features, methods)

winner_table <- results[[1]]
means <- results[[2]]
stds <- results[[3]]

``` 

```{r, message=FALSE, warning=FALSE, echo=FALSE, results="asis", echo=F, cache=F}

features<-c(0.01727359,0.00948178,0.03307109,0.05000035,0.01613514,0.010687,0.03511389,0.03009357,0.00699367,0.01803467,0.05204355,0.00998826,0.00402892,0.0296485, 0.02048253,0.00966048,0.03015889,0.05304506,0.01780573,0.0106906, 0.03407022,0.02817068,0.00460557,0.01990823,0.03633044,0.00707903,0.00348061,0.02476411,0.0066104, 0.00685614,0.01110999,0.00745441,0.0103241, 0.01173094,0.02497724,0.0054846,0.00183079,0.00366257,0.00253228,0.0024047, 0.00146763,0.00502182,0.00354396,0.00192363,0.00427153,0.0058273, 0.00326149,0.00187765,0.0046473, 0.01316245,0.00578763,0.01958605,0.03843529,0.00999519,0.00347232,0.03095239,0.01946466,0.00605859,0.02236143,0.03276835,0.01292005,0.00378915,0.03157981)

methods <- c("broof","lazy","bert","lxt","svm","nb","knn","rf","xt")

features <- matrix(features,byrow = T, nrow=9)

results <- method_importance(methods, features, distance="Spearman")
m <- results[[1]]
rank <- results[[2]]
m <- `rownames<-`(m, methods)
tab <- xtable(t(m[rank$top.list,]), caption = "Importância de cada classificador no stacking COMBALL para o conjunto de dados 4UNI", label = "tab:imp4uni")
print(tab)

results <- fff(features, methods)

winner_table <- rbind(winner_table, results[[1]])
means <- rbind(means, results[[2]])
stds <- rbind(stds, results[[3]])
``` 

```{r, message=FALSE, warning=FALSE, echo=FALSE, results="asis", echo=F, cache=F}


features<-c(0.00576379,0.01256447,0.0097961, 0.02763889,0.00294047,0.00680401,0.00798044,0.01906577,0.01337437,0.00492835,0.01177919,0.00497994,0.01472283,0.01353151,0.02992713,0.00100785,0.00513719,0.00612622,0.02919084,0.02564867,0.00258663,0.0199351, 0.00553538,0.01444126,0.01259737,0.02921041,0.00276867,0.00748017,0.00879916,0.02054374,0.01886737,0.00480581,0.01665388,0.00406514,0.01159068,0.00803178,0.01129446,0.00086012,0.00482741,0.00649418,0.01588574,0.00953806,0.0025302, 0.0105018, 0.00543622,0.00518523,0.00550946,0.00497894,0.00463245,0.00498848,0.0049471, 0.00506821,0.00505904,0.00453715,0.00592229,0.00455162,0.01379541,0.01115291,0.03636996,0.00229188,0.00724287,0.00765677,0.02498533,0.02550274,0.00382257,0.01356729,0.00301972,0.00726196,0.00737522,0.01336878,0.00111708,0.00478237,0.00501063,0.00968544,0.0064602, 0.00274532,0.0107334, 0.00429166,0.00963689,0.00867814,0.02229234,0.00106916,0.00502342,0.00499448,0.01577203,0.01171738,0.00313106,0.01518078,0.00466445,0.00987442,0.01216422,0.01675981,0.00097036,0.00554258,0.00612925,0.02589354,0.01332404,0.0030369, 0.01833656)

methods <- c("broof","lazy","bert","lxt","svm","nb","knn","rf","xt")
features <- matrix(features,byrow = T, nrow=9)
results <- method_importance(methods, features, distance="Spearman")
m <- results[[1]]
rank <- results[[2]]
m <- `rownames<-`(m, methods)
tab <- xtable(t(m[rank$top.list,]), caption = "Importância de cada classificador no stacking COMBALL para o conjunto de dados ACM", label = "tab:impacm")
print(tab)

results <- fff(features, methods)

winner_table <- rbind(winner_table, results[[1]])
means <- rbind(means, results[[2]])
stds <- rbind(stds, results[[3]])
``` 

```{r, message=FALSE, warning=FALSE, echo=FALSE, results="asis", echo=F, cache=F}
features<-c(8.54744801e-03, 1.06391848e-03, 9.81983517e-04, 1.57141469e-03, 1.05937680e-03, 8.23658841e-05, 1.08407314e-03, 2.62108229e-04, 2.74115013e-04, 1.42621774e-03, 1.35002025e-03, 1.56014165e-04, 2.50360795e-03, 9.16339027e-04, 1.23200761e-04, 1.34127858e-03, 1.95814155e-04, 2.86018840e-03, 1.89076931e-04, 1.27034383e-03, 3.81818619e-04, 8.00345537e-03, 5.11764313e-04, 1.90910060e-03, 1.12583790e-03, 1.06438413e-03, 3.57782230e-03, 3.15026945e-04, 7.92056461e-05, 5.43688891e-04, 4.62014215e-04, 8.80327822e-04, 5.58058240e-04, 3.03701305e-04, 2.96314168e-03, 1.07842065e-03, 1.18685173e-03, 2.35078595e-04, 9.27595680e-04, 2.91537222e-04, 6.90576674e-04, 4.52734421e-04, 1.10046517e-04, 1.37391052e-03, 5.69303721e-04, 6.76909150e-04, 2.13698950e-03, 1.67033743e-03, 3.20109451e-04, 1.25590389e-03, 3.04431730e-04, 2.05287665e-04, 1.92276413e-04, 3.40796903e-04, 1.62058028e-03, 5.52769276e-04, 1.35414722e-04, 5.95152679e-05, 6.01571864e-04, 6.67149036e-04, 4.30753573e-04, 2.54734409e-04, 3.28468588e-04, 1.65027744e-04, 3.27756447e-04, 5.56281326e-04, 1.05365214e-03, 6.42078147e-04, 7.15780700e-04, 1.14645224e-03, 1.02101414e-04, 2.42173165e-03, 4.72123323e-04, 4.68772695e-04, 1.37683003e-03, 6.15226927e-04, 4.80149516e-04, 6.12872629e-04, 2.04623463e-03, 1.26991677e-04, 2.51148628e-04, 3.48581354e-04, 2.94246348e-04, 5.52921619e-04, 4.87276020e-03, 1.26636362e-03, 2.72818747e-03, 8.03964804e-04, 7.30382199e-04, 5.37910373e-04, 3.18155099e-02, 1.28035799e-03, 1.12888363e-03, 1.52961747e-03, 1.14485412e-03, 4.04647886e-05, 7.91750639e-04, 1.78843038e-04, 3.92178249e-04, 1.31924405e-03, 8.26300452e-04, 1.47641651e-04, 2.69570029e-03, 1.21519596e-03, 1.13930342e-04, 1.21625355e-03, 1.03901006e-04, 1.07190059e-02, 1.21595761e-04, 3.28086776e-03, 3.03697007e-04, 7.34728350e-02, 2.77180312e-04, 6.99906559e-04, 2.76875752e-03, 2.09360891e-03, 5.21523980e-03, 2.53406815e-04, 1.00856277e-04, 4.21397936e-04, 3.19239318e-04, 5.75641857e-04, 4.44718423e-04, 2.02533072e-04, 5.54352942e-03, 9.15325916e-04, 6.80338904e-04, 1.43343779e-04, 1.04011851e-03, 1.92873355e-04, 4.76096106e-04, 2.23228623e-04, 1.98735596e-04, 2.41053473e-03, 3.74009947e-04, 1.15910157e-03, 5.43509143e-03, 2.21442334e-03, 1.97950352e-04, 1.36688494e-03, 1.48982155e-04, 9.70351424e-05, 1.84583029e-04, 5.43341004e-04, 2.55188147e-03, 3.34154771e-04, 1.14167000e-04, 1.30766202e-04, 8.29880243e-04, 2.17750510e-04, 1.58590584e-04, 1.43816786e-04, 1.33854945e-04, 3.07258510e-05, 2.82744486e-04, 5.46850882e-04, 1.20508865e-03, 4.13128104e-04, 1.16395678e-03, 6.14165361e-04, 4.46934900e-05, 4.81463416e-03, 4.70641679e-04, 1.07181934e-03, 2.36468361e-03, 1.05448878e-03, 9.49298494e-04, 3.02290635e-04, 1.45887928e-03, 1.66417220e-04, 2.16380107e-04, 5.22036281e-04, 3.59650016e-04, 5.26610679e-04, 4.33512255e-03, 1.75603437e-03, 3.23070145e-03, 4.49359349e-04, 1.06736784e-03, 5.28186940e-04, 1.38587917e-02, 1.16253387e-03, 8.07713410e-04, 1.34371189e-03, 1.10656952e-03, 1.32205701e-04, 1.12279208e-03, 2.60787926e-04, 3.85518628e-04, 1.98319051e-03, 1.21856085e-03, 1.80737143e-04, 2.31096149e-03, 8.64080963e-04, 1.85708659e-04, 1.52775706e-03, 2.02084507e-04, 2.82161450e-03, 1.74181731e-04, 1.22586530e-03, 4.10745785e-04, 1.42315153e-02, 4.88502295e-04, 1.83869474e-03, 1.12273362e-03, 1.21163726e-03, 3.28778006e-03, 3.68367265e-04, 6.31610223e-05, 6.11270747e-04, 5.19478398e-04, 1.02604792e-03, 7.08932826e-04, 2.99485747e-04, 3.64643244e-03, 8.05564418e-04, 1.13838181e-03, 3.13036203e-04, 8.60212793e-04, 2.87292804e-04, 7.23297999e-04, 4.42431691e-04, 1.73462911e-04, 1.33291991e-03, 3.96686733e-04, 6.48168433e-04, 2.80105730e-03, 2.79253598e-03, 3.41155554e-04, 1.32117953e-03, 3.34269490e-04, 2.12439784e-04, 2.45839187e-04, 3.69568161e-04, 1.57502535e-03, 5.21365946e-04, 1.69681739e-04, 1.12103578e-04, 8.32234355e-04, 6.15374529e-04, 4.44961399e-04, 1.99565780e-04, 3.58632766e-04, 1.77214719e-04, 3.94524353e-04, 5.12125252e-04, 1.33219101e-03, 8.07010882e-04, 8.40294950e-04, 1.58742908e-03, 8.69315957e-05, 2.50254860e-03, 5.79052230e-04, 5.38911752e-04, 1.52430627e-03, 5.84179753e-04, 4.73127188e-04, 5.23546154e-04, 1.56775748e-03, 1.34444505e-04, 2.54856551e-04, 3.73230027e-04, 3.37202540e-04, 6.76972404e-04, 5.56021591e-03, 1.26398062e-03, 3.71225365e-03, 6.95795790e-04, 7.15000440e-04, 5.25579395e-04, 3.10972034e-02, 7.92402590e-04, 3.52547642e-04, 9.31360248e-04, 6.21642692e-04, 1.42656844e-05, 3.50164983e-04, 5.97826055e-05, 1.34032521e-04, 5.81317259e-04, 7.03642301e-04, 5.68153979e-05, 1.83836514e-03, 4.20980975e-04, 4.55038974e-05, 8.28261751e-04, 5.04001863e-05, 3.42761485e-03, 6.71051541e-05, 1.40294478e-03, 1.72480227e-04, 7.01729282e-02, 2.13318262e-04, 5.07806196e-04, 8.03540960e-04, 5.97500133e-04, 4.21948462e-03, 5.82649285e-05, 2.71209098e-05, 1.97238221e-04, 1.31732229e-04, 2.67398745e-04, 2.31701930e-04, 1.03381031e-04, 4.23058707e-03, 5.10156865e-04, 4.33910322e-04, 4.32601897e-05, 4.95670484e-04, 7.25222890e-05, 2.06499661e-04, 1.64064613e-04, 6.17670761e-05, 8.57765319e-04, 1.97154586e-04, 4.46929631e-04, 4.38671747e-03, 3.71592002e-03, 1.08619940e-04, 5.30226620e-04, 1.70764994e-04, 2.42660899e-05, 7.45766712e-05, 1.28407910e-04, 1.24255539e-03, 2.55991712e-04, 1.39397844e-05, 4.88934459e-05, 3.27223485e-04, 2.55932512e-04, 5.05711890e-05, 5.55193863e-05, 5.70665677e-05, 9.57637604e-05, 9.72839960e-05, 1.96219615e-04, 5.66124906e-04, 2.63346301e-04, 3.76833920e-04, 1.86173551e-04, 1.77159803e-06, 2.32417630e-03, 1.87509122e-04, 2.58827973e-04, 7.59549949e-04, 4.00684813e-04, 2.78416221e-04, 1.35984340e-04, 7.07003913e-04, 2.91473988e-05, 8.98536221e-05, 1.49137612e-04, 1.25249389e-04, 2.31695032e-04, 2.95085294e-03, 8.85096637e-04, 2.05809866e-03, 3.74455689e-04, 4.52649128e-04, 2.39758328e-04, 5.08585634e-03, 9.93996102e-04, 8.95148404e-04, 8.31324855e-04, 8.68271170e-04, 6.56669968e-04, 7.18060447e-04, 7.97788055e-04, 8.01734743e-04, 9.09638089e-04, 8.30195127e-04, 7.02854539e-04, 8.43258825e-04, 1.41249011e-03, 8.57136609e-04, 7.94425607e-04, 7.49309440e-04, 1.42418868e-03, 6.83595424e-04, 1.26797968e-03, 8.39719280e-04, 2.10587821e-03, 9.31246450e-04, 1.12314681e-03, 8.66893476e-04, 9.76421264e-04, 1.03334717e-03, 9.17800502e-04, 7.40695135e-04, 9.76746435e-04, 9.87488834e-04, 7.57233175e-04, 7.32957347e-04, 6.51688065e-04, 1.12623472e-03, 7.79527375e-04, 9.73754955e-04, 1.15029923e-03, 6.88774388e-04, 8.91084253e-04, 9.37831839e-04, 6.55332844e-04, 7.96111097e-04, 1.02076559e-03, 1.21388503e-03, 8.91607484e-04, 1.17697822e-03, 9.58579205e-04, 1.22215269e-03, 1.13740550e-03, 1.01260679e-03, 1.01440761e-03, 8.34982644e-04, 9.74422898e-04, 1.21803069e-03, 7.91050581e-04, 9.44402986e-04, 7.35789325e-04, 1.32319498e-03, 1.25988563e-03, 9.45829929e-04, 1.00392829e-03, 8.10903092e-04, 7.21017269e-04, 9.19601695e-04, 9.15342825e-04, 7.24038496e-04, 8.03570900e-04, 1.50655992e-03, 9.67019245e-04, 8.09916273e-04, 1.60029381e-03, 7.88571234e-04, 8.43347737e-04, 8.75287144e-04, 7.95823933e-04, 7.76315029e-04, 1.08392287e-03, 7.63845449e-04, 6.56224634e-04, 8.42259721e-04, 7.86466013e-04, 8.79147407e-04, 1.21399333e-03, 2.35826740e-03, 8.94214756e-04, 1.01067239e-03, 6.19991003e-04, 1.40406452e-03, 1.10767216e-03, 4.05914093e-02, 4.23979432e-04, 2.13207889e-04, 7.41984860e-04, 1.79800043e-04, 1.08257795e-06, 1.25017114e-04, 0.00000000e+00, 6.56883645e-06, 6.38518600e-04, 3.01527934e-04, 4.72954414e-06, 2.56659436e-04, 6.13185204e-05, 0.00000000e+00, 4.83626321e-04, 2.09952770e-05, 1.80457531e-03, 0.00000000e+00, 5.19546381e-04, 4.15521025e-05, 1.50693086e-02, 3.33756182e-05, 2.56931672e-04, 2.83278896e-04, 2.47362592e-04, 4.99548989e-04, 2.71133987e-06, 0.00000000e+00, 2.07133088e-05, 2.33970655e-05, 1.61070665e-04, 4.73674766e-05, 8.05223328e-06, 4.54348131e-03, 1.55714280e-04, 1.24180399e-04, 0.00000000e+00, 4.87706013e-04, 3.73614582e-06, 1.53279239e-04, 1.67591301e-05, 0.00000000e+00, 9.85677292e-05, 7.82447950e-06, 1.01048826e-04, 1.12917034e-03, 1.12282273e-03, 1.53252008e-06, 4.96294557e-04, 2.19334439e-06, 4.65803609e-06, 0.00000000e+00, 2.22317494e-05, 3.21314752e-04, 4.83887233e-05, 5.26389052e-06, 0.00000000e+00, 5.96567367e-05, 6.18640458e-05, 7.97980177e-06, 1.03650002e-06, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.62673841e-05, 2.31440359e-04, 1.84352151e-04, 3.69704620e-05, 5.45028573e-05, 3.13640221e-07, 1.68058660e-03, 4.29806635e-05, 5.49497781e-05, 1.83634141e-04, 5.70527269e-05, 3.28013273e-05, 6.39191259e-05, 4.65318524e-04, 2.48798619e-06, 5.11945952e-06, 2.21197035e-05, 2.96485800e-05, 2.18827891e-04, 2.22938408e-03, 1.51395223e-04, 2.99500655e-04, 1.59926285e-04, 1.80022206e-04, 1.83384298e-04, 7.83058234e-04, 8.94392652e-04, 4.17847280e-04, 5.52294168e-04, 2.56026600e-04, 4.29342016e-06, 1.56584735e-03, 2.44835580e-05, 8.69788684e-06, 3.35422312e-04, 1.94359229e-04, 1.26599977e-05, 6.48568371e-04, 5.26189397e-04, 0.00000000e+00, 1.54819676e-03, 8.50224153e-06, 8.43140543e-04, 0.00000000e+00, 8.74156337e-04, 1.07936333e-04, 7.73012904e-04, 5.03638928e-05, 3.67517296e-04, 4.26696303e-04, 4.32301043e-04, 1.23610866e-03, 4.00176797e-05, 1.86324275e-06, 1.73887770e-04, 2.29397362e-04, 1.49298405e-04, 2.17242091e-04, 2.23642497e-05, 1.44323663e-03, 2.52479347e-04, 6.88568423e-04, 1.47745873e-05, 1.21776496e-03, 2.36533202e-05, 3.52550908e-04, 2.08537131e-04, 1.52196431e-05, 1.10564253e-03, 1.98833056e-05, 1.98775786e-04, 2.85641323e-03, 7.65353277e-04, 1.49152180e-04, 2.74491544e-04, 4.55836604e-05, 2.06460360e-05, 0.00000000e+00, 7.67186367e-05, 6.96879367e-04, 6.00411420e-04, 2.56261874e-05, 7.36628860e-06, 3.02372813e-04, 1.21922600e-04, 4.53559438e-05, 1.67595356e-05, 2.49707967e-05, 0.00000000e+00, 2.06867579e-05, 1.99343312e-04, 2.48249324e-04, 1.30917677e-04, 2.00090992e-04, 4.34406090e-04, 3.65579244e-06, 1.67565794e-03, 1.91172610e-04, 8.93842072e-05, 3.01376969e-04, 1.16769235e-04, 4.95584763e-05, 2.20257227e-04, 9.22818329e-04, 3.60955772e-06, 2.15527527e-05, 3.96783838e-05, 2.64534011e-05, 3.03936175e-04, 7.03300339e-04, 5.39998135e-04, 4.34057888e-04, 2.76828770e-04, 2.15091268e-04, 4.25931944e-04, 9.33908596e-03, 3.68543767e-04, 5.50296473e-04, 1.16923398e-03, 6.27178186e-04, 1.84098424e-05, 8.62298397e-04, 7.65570345e-05, 1.37710683e-04, 2.31979896e-03, 4.42334410e-04, 7.14077461e-05, 1.88982314e-03, 3.96900309e-04, 4.21345736e-05, 5.36382591e-04, 5.23121833e-05, 7.69521488e-03, 8.69154372e-05, 2.04055849e-03, 2.00873861e-04, 3.17595803e-02, 2.90628559e-04, 4.30009452e-04, 1.27321227e-03, 1.21918810e-03, 4.70340949e-03, 1.81364752e-04, 2.51961518e-05, 1.31710160e-04, 2.93034609e-04, 2.06703984e-04, 1.82067400e-04, 1.09828433e-04, 4.71737304e-03, 7.24313294e-04, 4.07654227e-04, 5.68881197e-05, 6.65736537e-04, 9.53742985e-05, 2.51505269e-04, 1.55368573e-04, 5.12175725e-05, 9.03745102e-04, 1.03737732e-04, 4.10887526e-04, 7.16983394e-03, 1.03206335e-03, 7.75245334e-05, 1.09265472e-03, 1.24323376e-04, 7.43051064e-05, 6.63244702e-05, 1.67989536e-04, 1.03735632e-03, 3.28753586e-04, 6.66953576e-05, 4.00022978e-05, 5.20864488e-04, 1.97282214e-04, 1.26488205e-04, 1.04151961e-04, 1.04596262e-04, 8.60648369e-05, 1.06454372e-04, 3.46313710e-04, 8.63342898e-04, 2.47176812e-04, 4.52094938e-04, 3.93800227e-04, 1.78162991e-05, 1.99942255e-03, 3.12282072e-04, 2.86243299e-04, 1.17799403e-03, 3.31791086e-04, 2.68016769e-04, 1.97030900e-04, 2.11027225e-03, 4.14507561e-05, 1.48866399e-04, 1.69887054e-04, 1.00844497e-04, 2.92874726e-04, 2.75196087e-03, 1.16093830e-03, 4.41196223e-03, 2.44187358e-04, 5.49005197e-04, 3.03458143e-04, 1.17226554e-02, 3.81701710e-04, 5.56840687e-04, 1.17181061e-03, 5.93756503e-04, 3.37339177e-05, 8.93411759e-04, 8.15498439e-05, 7.76490861e-05, 3.04905936e-03, 4.54229958e-04, 5.53238430e-05, 2.14843128e-03, 5.04764219e-04, 4.72257856e-05, 7.44374104e-04, 4.85829675e-05, 5.90092223e-03, 4.65251321e-05, 1.80128224e-03, 1.71596910e-04, 3.67787726e-02, 2.45391898e-04, 5.10877211e-04, 1.19754312e-03, 1.90026592e-03, 3.46880713e-03, 1.37961593e-04, 2.28815575e-05, 2.59048657e-04, 2.53424302e-04, 2.22777588e-04, 1.85553025e-04, 1.25612697e-04, 3.06813476e-03, 6.58525579e-04, 4.49034846e-04, 6.97620731e-05, 9.07068055e-04, 8.04781563e-05, 3.42739663e-04, 1.80377981e-04, 3.25715901e-05, 8.97861607e-04, 1.44584040e-04, 3.76813105e-04, 1.08662495e-02, 1.85871866e-03, 1.16293962e-04, 1.30961927e-03, 9.71365550e-05, 6.54375776e-05, 1.03772328e-04, 2.02713797e-04, 1.14141324e-03, 2.93843682e-04, 4.42496728e-05, 2.82183956e-05, 6.70690148e-04, 2.06995347e-04, 1.59165354e-04, 6.10244400e-05, 1.02074873e-04, 2.59902201e-05, 1.85355754e-04, 2.94734132e-04, 1.13804076e-03, 2.36845569e-04, 4.20591490e-04, 5.00885615e-04, 3.28658089e-05, 2.15064684e-03, 2.15269836e-04, 3.01956995e-04, 1.25261801e-03, 3.89228905e-04, 2.12766181e-04, 1.63923275e-04, 3.71521432e-03, 6.17002138e-05, 8.88904329e-05, 2.22480260e-04, 1.46757473e-04, 3.01549598e-04, 2.81228071e-03, 1.00909366e-03, 4.01928015e-03, 3.36330417e-04, 4.12323032e-04, 2.97761869e-04)

methods <- c("broof","lazy","bert","lxt","svm","nb","knn","rf","xt")
features <- matrix(features,byrow = T, nrow=9)

results <- fff(features, methods)

winner_table <- rbind(winner_table, results[[1]])
means <- rbind(means, results[[2]])
stds <- rbind(stds, results[[3]])

means <- round(means*100, digits = 2)
stds <- round(stds*100, digits = 2)

print_meas(t(means), t(stds), methods, c("20NG", "4UNI", "ACM", "REUTERS90"), c("importance"), t(winner_table))


means <- t(means)
scores = array(0, 9)
for(m in 1:dim(means)[1]){
  for(j in 1:dim(means)[2]){
    scores[m] <- scores[m] + sum(means[,j] <= means[m,j]) - 1
  }
}

ord <- order(scores, decreasing = T)
print(xtable(cbind(methods[ord], scores[ord])))

#results <- method_importance(methods, features, distance="Kendall")
#m <- results[[1]]
#rank <- results[[2]]
#m <- `rownames<-`(m, methods)
#tab <- xtable(t(m[rank$top.list,]), caption = "Importância de cada classificador no stacking COMBALL para o conjunto de dados REUTERS90", label = "tab:impcomball")
#print(tab)
```

## Meta-level classifiers comparison

```{r, message=FALSE, warning=FALSE, echo=FALSE, results="asis", echo=F, cache=F}

dir_path = "~/Documents/Master\ Degree/Master\ Project/Implementation/LazyNN_RF/release/results/text/stacking/all/"


winning_counts <- build_table(dir_path, caption = "Comparação entre meta-classificadores com COMBALL", label = "tab:meta-class
")


tab <- xtable(winning_counts[order(apply(winning_counts, 1, sum), decreasing = T), ],
                caption = "Número de vezes que cada algoritmo foi o mais eficaz", label = "tab:win_count_meta-class")
print(tab)
```

